{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify configuration file\n",
    "\n",
    "All of your Twitter API tokens and keys, and Twitter screen name and password are stored in a file called *scripts/config_{your_name}.py*.  We give you a template file called *scripts/config.py* in the repo.  Change the name of this file to *scripts/config_{your_name}.py*, as we do with homework files.  Then put your Chrome driver path, Twitter username and password, along with your Twiiter API credentials are in the *scripts/config_{your_name}.py* file.  \n",
    "\n",
    "You can find the API credentials for your Twitter API account here: https://developer.twitter.com/en/apps.  Click on *Details* for your app, and then *Keys and Tokens*. \n",
    "\n",
    "The Twitter API credentials are called\n",
    "\n",
    "1. `APP_KEY`\n",
    "\n",
    "2. `APP_SECRET`\n",
    "\n",
    "3. `OAUTH_TOKEN`\n",
    "\n",
    "4. `OAUTH_TOKEN_SECRET`\n",
    "\n",
    "The Twitter login info is called\n",
    "\n",
    "1. `USER`\n",
    "\n",
    "2. `PASSWORD`\n",
    "\n",
    "The Chrome drive path is called\n",
    "\n",
    "1. `DRIVER_PATH`\n",
    "\n",
    "I recommend the `DRIVER_PATH` be something like `DRIVER_PATH = 'scripts/chromedriver_win32/chromedriver.exe'`  Basically, create a folder in the *scripts* folder and put the drive .exe file in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages\n",
    "\n",
    "We will need:\n",
    "1. `twython` - this package lets you connect to the Twitter API. \n",
    "\n",
    "2. `selenium` - this package lets you crawl websites.\n",
    "\n",
    "3. `chromedriver_autoinstaller` - this package installs the chrome driver you download.\n",
    "\n",
    "4. Chrome driver - this is a software that lets us do the webcrawling with `selenium`. You have to download a Chrome driver from https://chromedriver.chromium.org/downloads.  Check to make sure your driver matches your version of Chrome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install twython --upgrade --user\n",
    "!pip install selenium --upgrade --user\n",
    "!pip install chromedriver_autoinstaller --upgrade --user\n",
    "\n",
    "#You need to download your chrome driver too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "We will import the packages we installed, along with some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import sqlite3, sys, os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import codecs  #this let's us display tweets properly (emojis, etc.)\n",
    "\n",
    "#helper code\n",
    "import scripts.scraper_twitter_api as api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import configuration file\n",
    "\n",
    "Import your modified configuration file with the code `from scripts.config_{your_name} import *`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.config_lmdisch import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Tweets by Keyword with the Twitter API\n",
    "\n",
    "Next we will provide code to collect tweets that contain a keyword, or one of many in a set of keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection made to Twitter API for lmdisch\n"
     ]
    }
   ],
   "source": [
    "twitter = Twython(APP_KEY, APP_SECRET,OAUTH_TOKEN, OAUTH_TOKEN_SECRET);\n",
    "print(\"Connection made to Twitter API for \"+twitter.verify_credentials()['screen_name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list of query keywords\n",
    "\n",
    "Create a list `keywords` that has all the words you want to search for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['boycottchina', 'CCPvirus', 'chinavirus', 'chinesevirus', 'chinaliedpeopledied', \n",
    "            'ChinaEnemyToTheWorld', 'kungflu', 'wuhanvirus', 'xivirus', 'beijingbiden', 'bidenvirus',\n",
    "            'CovidHOAX', 'PLANdemic', 'Scamdemic', 'MedicalMartialLaw', 'stopaapihate', 'stopasianhate', \n",
    "            'stopasianhatecrimes', 'racism', 'asianstrong', 'asianpride', 'asianamerican', 'webelonghere', \n",
    "            'protectourelders', 'aapi', 'standforasians', 'wearenotavirus', 'indianvariant', 'southafricanvariant', \n",
    "            'britishvariant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect tweets for each keyword\n",
    "\n",
    "The tweets will be saved in a database file with name given by `fname`.  If you run this cell again with the same filename, new tweets will be added to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets will be saved to database data/final_project_tweets.db\n",
      "Querying keyword  boycottchina\n",
      "Insterting final batch of tweets. got  1012  to insert\n",
      "Querying keyword  CCPvirus\n",
      "Insterting final batch of tweets. got  1055  to insert\n",
      "Querying keyword  chinavirus\n",
      "Insterting final batch of tweets. got  1017  to insert\n",
      "Querying keyword  chinesevirus\n",
      "Insterting final batch of tweets. got  1067  to insert\n",
      "Querying keyword  chinaliedpeopledied\n",
      "No more results\n",
      "Insterting final batch of tweets. got  859  to insert\n",
      "Querying keyword  ChinaEnemyToTheWorld\n",
      "\tToo many requests, go sleep for 15 minutes\n",
      "\tWill start insterting tweets in the meantime, got  0  to insert\n",
      "No more results\n",
      "Insterting final batch of tweets. got  284  to insert\n",
      "Querying keyword  kungflu\n",
      "No more results\n",
      "Insterting final batch of tweets. got  152  to insert\n",
      "Querying keyword  wuhanvirus\n",
      "Insterting final batch of tweets. got  1038  to insert\n",
      "Querying keyword  xivirus\n",
      "No more results\n",
      "Insterting final batch of tweets. got  6  to insert\n",
      "Querying keyword  beijingbiden\n",
      "No more results\n",
      "Insterting final batch of tweets. got  804  to insert\n",
      "Querying keyword  bidenvirus\n",
      "No more results\n",
      "Insterting final batch of tweets. got  17  to insert\n",
      "Querying keyword  CovidHOAX\n",
      "No more results\n",
      "Insterting final batch of tweets. got  589  to insert\n",
      "Querying keyword  PLANdemic\n",
      "Insterting final batch of tweets. got  1073  to insert\n",
      "Querying keyword  Scamdemic\n",
      "Insterting final batch of tweets. got  1054  to insert\n",
      "Querying keyword  MedicalMartialLaw\n",
      "No more results\n",
      "Insterting final batch of tweets. got  25  to insert\n",
      "Querying keyword  stopaapihate\n",
      "Insterting final batch of tweets. got  1000  to insert\n",
      "Querying keyword  stopasianhate\n",
      "Insterting final batch of tweets. got  1000  to insert\n",
      "Querying keyword  stopasianhatecrimes\n",
      "Insterting final batch of tweets. got  1000  to insert\n",
      "Querying keyword  racism\n",
      "Insterting final batch of tweets. got  1000  to insert\n",
      "Querying keyword  asianstrong\n",
      "No more results\n",
      "Insterting final batch of tweets. got  4  to insert\n",
      "Querying keyword  asianpride\n",
      "No more results\n",
      "Insterting final batch of tweets. got  233  to insert\n",
      "Querying keyword  asianamerican\n",
      "Insterting final batch of tweets. got  1000  to insert\n",
      "Querying keyword  webelonghere\n",
      "No more results\n",
      "Insterting final batch of tweets. got  303  to insert\n",
      "Querying keyword  protectourelders\n",
      "No more results\n",
      "Insterting final batch of tweets. got  29  to insert\n",
      "Querying keyword  aapi\n",
      "Insterting final batch of tweets. got  1000  to insert\n",
      "Querying keyword  standforasians\n",
      "No more results\n",
      "Insterting final batch of tweets. got  234  to insert\n",
      "Querying keyword  wearenotavirus\n",
      "No more results\n",
      "Insterting final batch of tweets. got  6  to insert\n",
      "Querying keyword  indianvariant\n",
      "No more results\n",
      "Insterting final batch of tweets. got  58  to insert\n",
      "Querying keyword  southafricanvariant\n",
      "No more results\n",
      "Insterting final batch of tweets. got  295  to insert\n",
      "Querying keyword  britishvariant\n",
      "No more results\n",
      "Insterting final batch of tweets. got  10  to insert\n",
      "44132 tweets in database\n"
     ]
    }
   ],
   "source": [
    "fname = f\"data/final_project_tweets.db\"\n",
    "max_tweets = 1000\n",
    "df = api.keyword_tweets(twitter ,keywords,fname,max_tweets = max_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load database into a dataframe\n",
    "\n",
    "We create a connection `conn` to the database and then load the data into a dataframe with the `read_sql_query` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df has 42704 rows\n",
      "df has columns Index(['tweet_id', 'user_id', 'screen_name', 'created_at', 'text', 'geo_lat',\n",
      "       'geo_long', 'place_type', 'place_name', 'lang', 'source',\n",
      "       'retweet_count', 'favorite_count', 'retweet_status_id',\n",
      "       'reply_to_status_id', 'reply_to_user_id', 'reply_to_screen_name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(fname)\n",
    "df = pd.read_sql_query(\"SELECT * FROM tweet\", conn)\n",
    "\n",
    "print(f\"df has {len(df)} rows\")\n",
    "print(f\"df has columns {df.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at top retweeted tweets\n",
    "\n",
    "For fun, let's print out the top retweeted tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014086 retweets: @cyycoby: RT @BTS_twt: #StopAsianHate\n",
      "#StopAAPIHate https://t.co/mOmttkOpOt \n",
      "1014086 retweets: @Kpopermoon1: RT @BTS_twt: #StopAsianHate\n",
      "#StopAAPIHate https://t.co/mOmttkOpOt \n",
      "1014086 retweets: @Arely_twt: RT @BTS_twt: #StopAsianHate\n",
      "#StopAAPIHate https://t.co/mOmttkOpOt \n",
      "1014086 retweets: @Tho94375515: RT @BTS_twt: #StopAsianHate\n",
      "#StopAAPIHate https://t.co/mOmttkOpOt \n",
      "1014086 retweets: @aseret1111: RT @BTS_twt: #StopAsianHate\n",
      "#StopAAPIHate https://t.co/mOmttkOpOt \n",
      "1014086 retweets: @psyqchoo: RT @BTS_twt: #StopAsianHate\n",
      "#StopAAPIHate https://t.co/mOmttkOpOt \n",
      "1014086 retweets: @_jiminsquishy: RT @BTS_twt: #StopAsianHate\n",
      "#StopAAPIHate https://t.co/mOmttkOpOt \n",
      "1014086 retweets: @busanfriendboys: RT @BTS_twt: #StopAsianHate\n",
      "#StopAAPIHate https://t.co/mOmttkOpOt \n",
      "1014086 retweets: @BANGTAN88631746: RT @BTS_twt: #StopAsianHate\n",
      "#StopAAPIHate https://t.co/mOmttkOpOt \n",
      "1014086 retweets: @thu_tra_2k3: RT @BTS_twt: #StopAsianHate\n",
      "#StopAAPIHate https://t.co/mOmttkOpOt \n"
     ]
    }
   ],
   "source": [
    "ndisplay = 10\n",
    "c = 0\n",
    "for index, row in df.sort_values(by = ['retweet_count'],ascending = False).iterrows():\n",
    "    c+=1\n",
    "    text = codecs.decode(row.text, 'unicode_escape')\n",
    "    print(f\"{row.retweet_count} retweets: @{row.screen_name}: {text}\")\n",
    "    if c>=ndisplay:break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>geo_lat</th>\n",
       "      <th>geo_long</th>\n",
       "      <th>place_type</th>\n",
       "      <th>place_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>source</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_status_id</th>\n",
       "      <th>reply_to_status_id</th>\n",
       "      <th>reply_to_user_id</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1381700240030498816</td>\n",
       "      <td>1258672380689485827</td>\n",
       "      <td>BianchiDaniele8</td>\n",
       "      <td>2021-04-12 20:06:22</td>\n",
       "      <td>@lemondefr Quel chauvinisme de merde. Le const...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>fr</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.381608e+18</td>\n",
       "      <td>24744541.0</td>\n",
       "      <td>lemondefr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1381691539546640389</td>\n",
       "      <td>978319285838860288</td>\n",
       "      <td>tonydll8</td>\n",
       "      <td>2021-04-12 19:31:48</td>\n",
       "      <td>Boicottare i prodotti cinesi \\xe8 giusto perch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>it</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1381687827822444552</td>\n",
       "      <td>86651427</td>\n",
       "      <td>IRISH_BUILT905</td>\n",
       "      <td>2021-04-12 19:17:03</td>\n",
       "      <td>#ww2 #ww3 #BoycottChina history has ways of du...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1381680897288638466</td>\n",
       "      <td>1353806891000844293</td>\n",
       "      <td>ChuWestBaGa1</td>\n",
       "      <td>2021-04-12 18:49:30</td>\n",
       "      <td>@EpochTimes @EpochTimesHK #China_is_terrorist ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.381671e+18</td>\n",
       "      <td>29097819.0</td>\n",
       "      <td>EpochTimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1381677812747239427</td>\n",
       "      <td>1218157218253557760</td>\n",
       "      <td>Cindy01515332</td>\n",
       "      <td>2021-04-12 18:37:15</td>\n",
       "      <td>RT @JilLye3: In Sagaing,\\nYouths held #Boycott...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1.381454e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id              user_id      screen_name  \\\n",
       "0  1381700240030498816  1258672380689485827  BianchiDaniele8   \n",
       "1  1381691539546640389   978319285838860288         tonydll8   \n",
       "2  1381687827822444552             86651427   IRISH_BUILT905   \n",
       "3  1381680897288638466  1353806891000844293     ChuWestBaGa1   \n",
       "4  1381677812747239427  1218157218253557760    Cindy01515332   \n",
       "\n",
       "            created_at                                               text  \\\n",
       "0  2021-04-12 20:06:22  @lemondefr Quel chauvinisme de merde. Le const...   \n",
       "1  2021-04-12 19:31:48  Boicottare i prodotti cinesi \\xe8 giusto perch...   \n",
       "2  2021-04-12 19:17:03  #ww2 #ww3 #BoycottChina history has ways of du...   \n",
       "3  2021-04-12 18:49:30  @EpochTimes @EpochTimesHK #China_is_terrorist ...   \n",
       "4  2021-04-12 18:37:15  RT @JilLye3: In Sagaing,\\nYouths held #Boycott...   \n",
       "\n",
       "   geo_lat  geo_long place_type place_name lang  \\\n",
       "0      NaN       NaN       None       None   fr   \n",
       "1      NaN       NaN       None       None   it   \n",
       "2      NaN       NaN       None       None   en   \n",
       "3      NaN       NaN       None       None   en   \n",
       "4      NaN       NaN       None       None   en   \n",
       "\n",
       "                                              source  retweet_count  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...              0   \n",
       "1  <a href=\"https://mobile.twitter.com\" rel=\"nofo...              0   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...              0   \n",
       "3  <a href=\"https://mobile.twitter.com\" rel=\"nofo...              0   \n",
       "4  <a href=\"http://twitter.com/download/android\" ...             47   \n",
       "\n",
       "   favorite_count  retweet_status_id  reply_to_status_id  reply_to_user_id  \\\n",
       "0               0                NaN        1.381608e+18        24744541.0   \n",
       "1               0                NaN                 NaN               NaN   \n",
       "2               0                NaN                 NaN               NaN   \n",
       "3               1                NaN        1.381671e+18        29097819.0   \n",
       "4               0       1.381454e+18                 NaN               NaN   \n",
       "\n",
       "  reply_to_screen_name  \n",
       "0            lemondefr  \n",
       "1                 None  \n",
       "2                 None  \n",
       "3           EpochTimes  \n",
       "4                 None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Following Networks with Web Crawlers\n",
    "\n",
    "The `followers` and `following` modules contain functions to collect the followers and following of users using a web crawler.  We don't use the Twitter API because it is incredibly slow for collecting network data.\n",
    "\n",
    "When building your networks, it is easier to use the `following` module.  This way you avoid getting stuck on someone with 100 million followers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify followers module.\n",
    "\n",
    "The `following` and `followers` modules need to import your Twitter user name and password from the configuration file.  Since you will change the name of this file to *config_{your_name}.py*, you need to change the import line in *following.py* and *followers.py* from `from scripts.config import *` to  `from scripts.config_{your_name} import *`.  Then run the code `import scripts.following as Following` and `import scripts.followers as Followers`.\n",
    "\n",
    "*ANNOYING FACT*: Each time you hard reset your repo, the *followers.py* and *following.py* files are overwritten with the version on the repo.  This means you have to change this import line each time you do a hard reset.  If you are clever, maybe you can rename the files and find a way to import them. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.following as Following\n",
    "import scripts.followers as Followers\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect the following of a list of users.\n",
    "\n",
    "Create a list `screen_name` of all the screen names you want to collect following for.  The function `Following.Network.multi_fetch` will collect the following for each screen name.  This data is returned as a dataframe `df`, whose columns are `screen_name` and `following`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "screen_names = [\"JoeBiden\",\"JanetYellen\",\"POTUS\",\"SecDef\",\"KamalaHarris\",\"DrBiden\", \"BarackObama\"]\n",
    "df = Following.Network.multi_fetch(users=screen_names,max_count = 500)\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    print(f\"{row.screen_name}: {len(row.following)} following\")\n",
    "\n",
    "df.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create networkx object\n",
    "\n",
    "This code creates a networkx object `G` from `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "for index,row in df.iterrows():\n",
    "    u = row.screen_name\n",
    "    G.add_node(u)\n",
    "    for v in row.following:\n",
    "        if v in df.screen_name.tolist():\n",
    "            G.add_edge(v,u)\n",
    "            \n",
    "print(f\"Network has {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your network\n",
    "\n",
    "Save the networkx object `G` to a pickle file with name given by `fname` using the `write_gpickle` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/network_following_biden.pickle'\n",
    "nx.write_gpickle(G,fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load network and draw it\n",
    "\n",
    "Just to make sure we did everything correctly, load the network using the `read_gpickle` function, and draw it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gpickle(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_network_pos(G,pos,title_str):\n",
    "    node_size = 100\n",
    "    node_color = \"pink\"\n",
    "    width = 0.5\n",
    "    edge_color = \"white\"\n",
    "    bg_color = \"black\"\n",
    "\n",
    "    #2 points  drawing network with directed layout \n",
    "    fig = plt.figure(figsize= (8,6))\n",
    "    plt.subplot(1,1,1)\n",
    "    nx.draw(G, width=width,pos=pos ,node_color=node_color,\n",
    "            edge_color=edge_color,node_size=node_size,\n",
    "            connectionstyle='arc3',with_labels=True,font_color = 'white')\n",
    "    plt.title(title_str,color = \"white\")\n",
    "    fig.set_facecolor(bg_color)\n",
    "    plt.show()    \n",
    "    return 1\n",
    "\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "draw_network_pos(G,pos,\"Biden Following Network\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
